{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, ImageDraw\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m measure\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m label\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from skimage import measure\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage import label\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa \n",
    "import tensorflow as tf\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate,\n",
    "                                     Dropout, BatchNormalization, Activation, Add, Multiply, Reshape,\n",
    "                                     GlobalAveragePooling2D, Dense, LayerNormalization, MultiHeadAttention,\n",
    "                                     ZeroPadding2D)\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.losses import categorical_crossentropy, Loss\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = (128, 128)\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    pd = tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "print(physical_devices)\n",
    "print(pd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definiowanie funkcji pomocniczych**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(path):\n",
    "    images = []\n",
    "    jsons = []\n",
    "    for root, _, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(('.jpg', '.png')):\n",
    "                images.append(os.path.join(root, file))\n",
    "            elif file.endswith('.json'):\n",
    "                jsons.append(os.path.join(root, file))\n",
    "    return images, jsons\n",
    "\n",
    "def load_images(image_paths):\n",
    "    return [Image.open(path).convert(\"RGB\") for path in image_paths]\n",
    "\n",
    "def resize_images(images):\n",
    "    return [img.resize(IMAGE_SIZE) for img in images]\n",
    "\n",
    "def load_json_data(json_paths):\n",
    "    data = []\n",
    "    for json_path in json_paths:\n",
    "        with open(json_path, 'r') as f:\n",
    "            data.append(json.load(f))\n",
    "    return data\n",
    "\n",
    "def create_masks(image_size, nucleus_data, original_size=(1228, 1228), radius=3):\n",
    "    masks = []\n",
    "    for idx, nuclei in enumerate(nucleus_data):\n",
    "        mask = Image.new('L', image_size, 0)  \n",
    "        draw = ImageDraw.Draw(mask)\n",
    "        x_scale = image_size[0] / original_size[0]\n",
    "        y_scale = image_size[1] / original_size[1]\n",
    "\n",
    "        for nucleus in nuclei:\n",
    "            x = int(nucleus['x'] * x_scale)\n",
    "            y = int(nucleus['y'] * y_scale)\n",
    "            label_id = nucleus['label_id']\n",
    "\n",
    "            if label_id not in [1, 2, 3]:\n",
    "                print(f\"Uwaga: Niezidentyfikowana etykieta w jądrze {label_id} w masce {idx + 1}\")\n",
    "                continue  \n",
    "\n",
    "            draw.ellipse((x - radius, y - radius, x + radius, y + radius), fill=label_id)\n",
    "\n",
    "        masks.append(np.array(mask))\n",
    "\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funkcje do wstępnego przetwarzania obrazów i masek**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(images):\n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        img_array = np.array(img)\n",
    "        processed_images.append(img_array)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "def preprocess_masks(masks):\n",
    "    print(f\"Kształt masek przed kodowaniem one-hot: {masks.shape}\")\n",
    "    \n",
    "    if len(masks.shape) == 3:\n",
    "        masks_clipped = np.clip(masks.astype(int), 0, NUM_CLASSES - 1)\n",
    "        one_hot_encoded_masks = np.eye(NUM_CLASSES)[masks_clipped]   \n",
    "        one_hot_encoded_masks = one_hot_encoded_masks.reshape(masks.shape[0], masks.shape[1], masks.shape[2], NUM_CLASSES)\n",
    "    else:\n",
    "        raise ValueError(f\"Nieoczekiwany kształt masek: {masks.shape}\")\n",
    "    \n",
    "    print(f\"Kształt masek po kodowaniu one-hot: {one_hot_encoded_masks.shape}\")\n",
    "    \n",
    "    return one_hot_encoded_masks\n",
    "\n",
    "def preprocess_images_and_masks(images, masks):\n",
    "    print(f\"Kształt masek przed przetwarzaniem: {masks.shape}\")\n",
    "\n",
    "    images = preprocess_images(images)\n",
    "    \n",
    "    if masks.shape[-1] != NUM_CLASSES:\n",
    "        masks = preprocess_masks(masks)\n",
    "    else:\n",
    "        print(\"Maski są już zakodowane w formacie one-hot, pomijam kodowanie.\")\n",
    "    \n",
    "    print(f\"Kształt masek po przetworzeniu: {masks.shape}\")\n",
    "    \n",
    "    return images, masks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funkcje do filtrowania obrazów**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_images_with_min_cells(images, masks, min_cells=10):\n",
    "    filtered_images = []\n",
    "    filtered_masks = []\n",
    "    discarded_count = 0\n",
    "\n",
    "    for img, mask in zip(images, masks):\n",
    "        unique_labels = np.unique(mask)\n",
    "        cell_count = np.sum([np.sum(mask == label_id) for label_id in [1, 2, 3]])\n",
    "        if cell_count >= min_cells:\n",
    "            if img.size == mask.size * 3: \n",
    "                filtered_images.append(np.array(img))\n",
    "                filtered_masks.append(np.array(mask))\n",
    "        else:\n",
    "            discarded_count += 1\n",
    "\n",
    "    print(f\"Liczba odrzuconych obrazów: {discarded_count}\")\n",
    "\n",
    "    return np.array(filtered_images), np.array(filtered_masks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funkcje do kodowania masek**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_masks(masks, num_classes=NUM_CLASSES):\n",
    "    masks_clipped = np.clip(masks.squeeze().astype(int), 0, num_classes - 1)\n",
    "    one_hot_encoded_masks = np.eye(num_classes)[masks_clipped]\n",
    "    return one_hot_encoded_masks.reshape(masks.shape[0], masks.shape[1], masks.shape[2], num_classes)\n",
    "\n",
    "def clip_mask_values(mask_batch):\n",
    "    return np.clip(mask_batch, 0, NUM_CLASSES - 1)\n",
    "\n",
    "def create_train_generator(image_generator, mask_generator):\n",
    "    while True:\n",
    "        X = next(image_generator)\n",
    "        y = next(mask_generator)\n",
    "        y = clip_mask_values(y)\n",
    "        yield X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definiowanie funkcji strat i metryk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_categorical_crossentropy(class_weights):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = K.cast(y_true, 'float32')\n",
    "        y_pred = K.cast(y_pred, 'float32')\n",
    "\n",
    "        weights = K.constant(class_weights)\n",
    "        loss = y_true * K.log(y_pred + K.epsilon())\n",
    "        loss = loss * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "\n",
    "        return K.mean(loss)\n",
    "    return loss\n",
    "\n",
    "def dice_loss_multiclass(y_true, y_pred, smooth=1e-6):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "\n",
    "    axes = tuple(range(1, K.ndim(y_pred) - 1))\n",
    "    numerator = 2. * K.sum(y_pred * y_true, axes)\n",
    "    denominator = K.sum(K.square(y_pred) + K.square(y_true), axes)\n",
    "    dice = K.mean((numerator + smooth) / (denominator + smooth))\n",
    "    return 1 - dice\n",
    "\n",
    "# def combined_loss(class_weights):\n",
    "#     def loss(y_true, y_pred):\n",
    "#         loss_ce = weighted_categorical_crossentropy(class_weights)(y_true, y_pred)\n",
    "#         loss_dice = dice_loss_multiclass(y_true, y_pred)\n",
    "#         return 0.5 * loss_ce + 0.5 * loss_dice\n",
    "#     return loss\n",
    "\n",
    "class CombinedLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, class_weights, reduction=tf.keras.losses.Reduction.AUTO, name='CombinedLoss'):\n",
    "        super(CombinedLoss, self).__init__(reduction=reduction, name=name)\n",
    "        self.class_weights = K.constant(class_weights)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Compute weighted categorical crossentropy\n",
    "        y_true = K.cast(y_true, 'float32')\n",
    "        y_pred = K.cast(y_pred, 'float32')\n",
    "\n",
    "        weights = self.class_weights\n",
    "        loss_ce = y_true * K.log(y_pred + K.epsilon())\n",
    "        loss_ce = loss_ce * weights\n",
    "        loss_ce = -K.sum(loss_ce, -1)\n",
    "        loss_ce = K.mean(loss_ce)\n",
    "\n",
    "        # Compute dice loss\n",
    "        axes = tuple(range(1, K.ndim(y_pred) - 1))\n",
    "        numerator = 2. * K.sum(y_pred * y_true, axes)\n",
    "        denominator = K.sum(K.square(y_pred) + K.square(y_true), axes)\n",
    "        dice = K.mean((numerator + 1e-6) / (denominator + 1e-6))\n",
    "        loss_dice = 1 - dice\n",
    "\n",
    "        return 0.5 * loss_ce + 0.5 * loss_dice\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(CombinedLoss, self).get_config()\n",
    "        config.update({\n",
    "            'class_weights': self.class_weights.numpy().tolist(),\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "\n",
    "def iou_metric(y_true, y_pred):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3]) - intersection\n",
    "    iou = K.mean((intersection + 1e-6) / (union + 1e-6), axis=0)\n",
    "    return iou\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definiowanie funkcji modelu U-Net**\n",
    "\n",
    "*Bloki sieci*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, num_filters):\n",
    "    x = Conv2D(num_filters, (3, 3), padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.2)(x)  \n",
    "    x = Conv2D(num_filters, (3, 3), padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.35)(x)  \n",
    "    return x\n",
    "\n",
    "def max_pool(input_tensor):\n",
    "    return MaxPooling2D((2, 2), strides=2)(input_tensor)\n",
    "\n",
    "def upsample_block(input_tensor, skip_features, num_filters):\n",
    "    x = UpSampling2D(size=(2, 2))(input_tensor)\n",
    "    x = Conv2D(num_filters, (3, 3), padding='same', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    if x.shape[1] != skip_features.shape[1] or x.shape[2] != skip_features.shape[2]:\n",
    "        x = ZeroPadding2D(padding=((0, 1), (0, 1)))(x)\n",
    "    \n",
    "    x = concatenate([x, skip_features])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bloki uwagi i sekwencyjnej ekstytacji*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_block(x, g, inter_channel):\n",
    "    theta_x = Conv2D(inter_channel, kernel_size=2, strides=2, padding='same')(x)\n",
    "    phi_g = Conv2D(inter_channel, kernel_size=1, strides=1, padding='same')(g)\n",
    "    concat = Add()([theta_x, phi_g])\n",
    "    relu_concat = Activation('relu')(concat)\n",
    "    psi = Conv2D(1, kernel_size=1, strides=1, padding='same')(relu_concat)\n",
    "    sigmoid_psi = Activation('sigmoid')(psi)\n",
    "    upsample_sigmoid_psi = UpSampling2D(size=(2, 2))(sigmoid_psi)\n",
    "    upsample_sigmoid_psi = Conv2D(K.int_shape(x)[-1], kernel_size=1, padding='same')(upsample_sigmoid_psi)\n",
    "    attn_coefficients = Multiply()([x, upsample_sigmoid_psi])\n",
    "    return attn_coefficients\n",
    "\n",
    "def self_attention_block(input_tensor, num_heads=4):\n",
    "    norm_input = LayerNormalization()(input_tensor)\n",
    "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=64)(norm_input, norm_input)\n",
    "    attention_output = Add()([attention_output, input_tensor])\n",
    "    return attention_output\n",
    "\n",
    "def se_block(input_tensor, ratio=16):\n",
    "    channel_axis = -1\n",
    "    filters = input_tensor.shape[channel_axis]\n",
    "    se_shape = (1, 1, filters)\n",
    "    \n",
    "    se = GlobalAveragePooling2D()(input_tensor)\n",
    "    se = Reshape(se_shape)(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    \n",
    "    x = Multiply()([input_tensor, se])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Definicja U-Net i modelu*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(inputs, filterd_vector=[32, 64, 128, 256, 512]):\n",
    "    conv1 = conv_block(inputs, filterd_vector[0])\n",
    "    pool1 = max_pool(conv1)\n",
    "\n",
    "    conv2 = conv_block(pool1, filterd_vector[1])\n",
    "    pool2 = max_pool(conv2)\n",
    "\n",
    "    conv3 = conv_block(pool2, filterd_vector[2])\n",
    "    pool3 = max_pool(conv3)\n",
    "\n",
    "    conv4 = conv_block(pool3, filterd_vector[3])\n",
    "    pool4 = max_pool(conv4)\n",
    "\n",
    "    conv5 = conv_block(pool4, filterd_vector[4])\n",
    "\n",
    "    se_attention = self_attention_block(conv5)\n",
    "    se_attention = se_block(se_attention)\n",
    "\n",
    "    up6 = upsample_block(se_attention, attention_block(conv4, conv5, filterd_vector[3]), filterd_vector[3])\n",
    "    up7 = upsample_block(up6, attention_block(conv3, up6, filterd_vector[2]), filterd_vector[2])\n",
    "    up8 = upsample_block(up7, attention_block(conv2, up7, filterd_vector[1]), filterd_vector[1])\n",
    "    up9 = upsample_block(up8, attention_block(conv1, up8, filterd_vector[0]), filterd_vector[0])\n",
    "\n",
    "    return up9\n",
    "\n",
    "def stacked_unet(num_filters, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3), num_unets=1):\n",
    "    inputs = Input(input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    for _ in range(num_unets):\n",
    "        x = unet(x, num_filters)\n",
    "    outputs = Conv2D(NUM_CLASSES, (1, 1), activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funkcje treningu i ewaluacji**\n",
    "\n",
    "*Funkcja do trenowania modelu*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_images_np, train_masks_np, val_images_np, val_masks_np, test_images_np, test_masks_np, num_filters, epochs, batch_size=2, unet_size=1):\n",
    "    y_train_labels = np.argmax(train_masks_np, axis=-1).flatten()\n",
    "    class_counts = np.bincount(y_train_labels, minlength=NUM_CLASSES)\n",
    "    total_pixels = len(y_train_labels)\n",
    "    class_frequencies = class_counts / total_pixels\n",
    "    class_weights = 1.0 / (class_frequencies + 1e-6)\n",
    "    class_weights = class_weights / np.sum(class_weights)\n",
    "    print(\"Wagi klas:\", class_weights)\n",
    "\n",
    "    loss_function = CombinedLoss(class_weights)\n",
    "\n",
    "    model = stacked_unet(num_filters=num_filters, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3), num_unets=unet_size)\n",
    "\n",
    "    optimizer = AdamW(learning_rate=0.001, weight_decay=1e-5)\n",
    "\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss=loss_function, \n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), iou_metric])\n",
    "\n",
    "\n",
    "    save_folder = f'Model/{unet_size}_unets_{num_filters[-1]}_filters'\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    checkpoint = ModelCheckpoint(os.path.join(save_folder, f'best_model_{unet_size}_unets_{num_filters[-1]}_filters_{epochs}_epoch_{batch_size}_batch.h5'),\n",
    "                                 monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=11, restore_best_weights=True)  \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "    lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "    data_gen_args = dict(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='constant',\n",
    "        cval=0\n",
    "    )\n",
    "\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    seed = 42\n",
    "\n",
    "    image_generator = image_datagen.flow(\n",
    "        train_images_np,\n",
    "        batch_size=batch_size,\n",
    "        seed=seed,\n",
    "        shuffle=True)\n",
    "\n",
    "    mask_generator = mask_datagen.flow(\n",
    "        train_masks_np.astype(np.uint8),\n",
    "        batch_size=batch_size,\n",
    "        seed=seed,\n",
    "        shuffle=True)\n",
    "\n",
    "    train_generator = create_train_generator(image_generator, mask_generator)\n",
    "\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_images_np) // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(val_images_np, val_masks_np),\n",
    "        callbacks=[checkpoint, early_stopping, lr_scheduler]\n",
    "    )\n",
    "\n",
    "    return model, history\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def visualize_predictions(model, test_images, test_masks, num_examples=5):\n",
    "    predictions = model.predict(test_images)\n",
    "    y_pred_labels = np.argmax(predictions, axis=-1)\n",
    "    y_true_labels = np.argmax(test_masks, axis=-1)\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(test_images[i])\n",
    "        plt.title('Oryginalny obraz')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(y_true_labels[i])\n",
    "        plt.title('Prawdziwa maska')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(y_pred_labels[i])\n",
    "        plt.title('Predykcja modelu')\n",
    "\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Funkcje do uruchamiania treningu i wykresów*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(train_images_np, train_masks_np, val_images_np, val_masks_np, test_images_np, test_masks_np, filters_list, batch_size_list, epochs_list):\n",
    "    for i in range(1, 4):     \n",
    "        for num_filters in filters_list:\n",
    "            num_unets = i\n",
    "            for batch_size in batch_size_list:\n",
    "                for epochs in epochs_list:\n",
    "                    K.clear_session()\n",
    "                    print(f\"\\nTrening modelu z {num_unets} U-Net, {num_filters[-1]} filtrami, batch_size = {batch_size}, epochs = {epochs}\\n\")\n",
    "\n",
    "                    model, history = train_model(\n",
    "                        train_images_np, train_masks_np,\n",
    "                        val_images_np, val_masks_np,\n",
    "                        test_images_np, test_masks_np,\n",
    "                        num_filters=num_filters,\n",
    "                        epochs=epochs, batch_size=batch_size,\n",
    "                        unet_size=num_unets\n",
    "                    )\n",
    "\n",
    "                    \n",
    "                    save_folder = f'Model/{num_unets}_unets_{num_filters[-1]}_filters'\n",
    "                    plot_training_history(history, save_folder, filters=num_filters[-1], epochs=epochs)\n",
    "                    \n",
    "                    K.clear_session()      \n",
    "\n",
    "def plot_training_history(history, save_folder, filters, epochs):\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'], label='Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title(f'Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_folder, f'loss_{filters}_filters_{epochs}_epoch.png'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title(f'Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_folder, f'acc_{filters}_filters_{epochs}_epoch.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Funkcje do ewaluacji modelu*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cells(y_pred_labels, class_id):\n",
    "    labeled_array = measure.label(y_pred_labels == class_id, connectivity=1)\n",
    "    return np.max(labeled_array)\n",
    "\n",
    "def combine_pixels_for_all_classes(predictions):\n",
    "    results = {\n",
    "        \"Pozytywne\": 0,\n",
    "        \"Negatywne\": 0,\n",
    "        \"TLL\": 0\n",
    "    }\n",
    "    \n",
    "    for class_index, class_name in enumerate([\"Pozytywne\", \"Negatywne\", \"TLL\"], start=1):\n",
    "        class_mask = predictions[..., class_index]\n",
    "        \n",
    "        labeled_array, num_features = label(class_mask > 0.5)\n",
    "        \n",
    "        results[class_name] = num_features\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_model_with_channels(model, model_name, test_images_np, test_masks_np, csv_filename='evaluation_results.csv'):\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "    from skimage.measure import label\n",
    "    import csv\n",
    "\n",
    "    predictions = model.predict(test_images_np)\n",
    "    y_pred_labels = np.argmax(predictions, axis=-1)\n",
    "    y_true_labels = np.argmax(test_masks_np, axis=-1)\n",
    "\n",
    "    # Spłaszczanie tablic etykiet\n",
    "    y_true_labels_flat = y_true_labels.flatten()\n",
    "    y_pred_labels_flat = y_pred_labels.flatten()\n",
    "\n",
    "    # Upewnij się, że etykiety są typu całkowitego\n",
    "    y_true_labels_flat = y_true_labels_flat.astype(np.int32)\n",
    "    y_pred_labels_flat = y_pred_labels_flat.astype(np.int32)\n",
    "\n",
    "    # Uzyskanie raportu klasyfikacji jako słownik\n",
    "    report = classification_report(\n",
    "        y_true_labels_flat,\n",
    "        y_pred_labels_flat,\n",
    "        labels=[0, 1, 2, 3],\n",
    "        target_names=['Background', 'Pozytywne', 'Negatywne', 'TLL'],\n",
    "        output_dict=True,\n",
    "        zero_division=0  # Zapobieganie dzieleniu przez zero\n",
    "    )\n",
    "    # Wydrukowanie raportu klasyfikacji\n",
    "    print(classification_report(\n",
    "        y_true_labels_flat,\n",
    "        y_pred_labels_flat,\n",
    "        labels=[0, 1, 2, 3],\n",
    "        target_names=['Background', 'Pozytywne', 'Negatywne', 'TLL'],\n",
    "        zero_division=0\n",
    "    ))\n",
    "\n",
    "    # Funkcja do liczenia indywidualnych komórek (obiektów)\n",
    "    def count_cells(mask, class_id):\n",
    "        labeled_mask = label(mask == class_id, connectivity=1)\n",
    "        return np.max(labeled_mask)\n",
    "\n",
    "    # Liczenie indywidualnych komórek w danych rzeczywistych\n",
    "    total_positive_cells = count_cells(y_true_labels, 1)\n",
    "    total_negative_cells = count_cells(y_true_labels, 2)\n",
    "    total_tll_cells = count_cells(y_true_labels, 3)\n",
    "    total_cells = total_positive_cells + total_negative_cells + total_tll_cells\n",
    "\n",
    "    # Liczenie indywidualnych komórek w predykcjach modelu\n",
    "    detected_positive_cells = count_cells(y_pred_labels, 1)\n",
    "    detected_negative_cells = count_cells(y_pred_labels, 2)\n",
    "    detected_tll_cells = count_cells(y_pred_labels, 3)\n",
    "    total_detected_cells = detected_positive_cells + detected_negative_cells + detected_tll_cells\n",
    "\n",
    "    # Obliczanie procentów wykrytych komórek\n",
    "    positive_percentage = (detected_positive_cells / total_positive_cells) * 100 if total_positive_cells > 0 else 0\n",
    "    negative_percentage = (detected_negative_cells / total_negative_cells) * 100 if total_negative_cells > 0 else 0\n",
    "    tll_percentage = (detected_tll_cells / total_tll_cells) * 100 if total_tll_cells > 0 else 0\n",
    "    total_detected_percentage = (total_detected_cells / total_cells) * 100 if total_cells > 0 else 0\n",
    "\n",
    "    print(f\"Liczba wszystkich komórek: {total_cells}\")\n",
    "    print(f\"Liczba pozytywnych komórek: {total_positive_cells}\")\n",
    "    print(f\"Liczba negatywnych komórek: {total_negative_cells}\")\n",
    "    print(f\"Liczba komórek TLL: {total_tll_cells}\")\n",
    "    print(f\"Wykryte pozytywne komórki: {detected_positive_cells}\")\n",
    "    print(f\"Wykryte negatywne komórki: {detected_negative_cells}\")\n",
    "    print(f\"Wykryte komórki TLL: {detected_tll_cells}\")\n",
    "    print(f\"Procent wykrytych pozytywnych komórek: {positive_percentage:.2f}%\")\n",
    "    print(f\"Procent wykrytych negatywnych komórek: {negative_percentage:.2f}%\")\n",
    "    print(f\"Procent wykrytych komórek TLL: {tll_percentage:.2f}%\")\n",
    "    print(f\"Procent wykrytych wszystkich komórek: {total_detected_percentage:.2f}%\")\n",
    "\n",
    "    \n",
    "    precision = precision_score(y_true_labels_flat, y_pred_labels_flat, labels=[1, 2, 3], average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true_labels_flat, y_pred_labels_flat, labels=[1, 2, 3], average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true_labels_flat, y_pred_labels_flat, labels=[1, 2, 3], average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"Precyzja: {precision:.2f}\")\n",
    "    print(f\"Czułość (Recall): {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "    # Zapisywanie wyników do pliku CSV\n",
    "    with open(csv_filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if file.tell() == 0:\n",
    "            writer.writerow([\n",
    "                \"Model\", \"Liczba wszystkich komórek\", \"Liczba pozytywnych komórek\", \n",
    "                \"Liczba negatywnych komórek\", \"Liczba komórek TLL\", \"Wykryte pozytywne komórki\", \n",
    "                \"Wykryte negatywne komórki\", \"Wykryte komórki TLL\", \"Procent wykrytych pozytywnych komórek\", \n",
    "                \"Procent wykrytych negatywnych komórek\", \"Procent wykrytych komórek TLL\", \n",
    "                \"Procent wykrytych wszystkich komórek\", \"Precyzja\", \"Czułość\", \"F1-Score\"\n",
    "            ])\n",
    "        writer.writerow([\n",
    "            model_name, total_cells, total_positive_cells, total_negative_cells, total_tll_cells,\n",
    "            detected_positive_cells, detected_negative_cells, detected_tll_cells,\n",
    "            positive_percentage, negative_percentage, tll_percentage, total_detected_percentage,\n",
    "            precision, recall, f1\n",
    "        ])\n",
    "\n",
    "\n",
    "def evaluate_models_in_folders(base_folder, test_images_np, test_masks_np):\n",
    "    for root, dirs, files in os.walk(base_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.h5'):  \n",
    "                model_path = os.path.join(root, file)\n",
    "                print(f\"\\nOcena modelu: {model_path}\")\n",
    "\n",
    "                model = load_model(model_path, custom_objects={'CombinedLoss': CombinedLoss, 'iou_metric': iou_metric})\n",
    "                model_name = os.path.basename(model_path)\n",
    "\n",
    "                evaluate_model_with_channels(model, model_name, test_images_np, test_masks_np)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Przygotowanie danych**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba załadowanych obrazów treningowych: 1656\n",
      "Liczba załadowanych obrazów testowych: 700\n",
      "Liczba obrazów treningowych po zmianie rozmiaru: 1656\n",
      "Liczba obrazów testowych po zmianie rozmiaru: 700\n",
      "Kształt obrazów treningowych: (1656, 128, 128, 3)\n",
      "Kształt masek treningowych: (1656, 128, 128)\n",
      "Kształt obrazów testowych: (700, 128, 128, 3)\n",
      "Kształt masek testowych: (700, 128, 128)\n",
      "Liczba odrzuconych obrazów: 38\n",
      "Liczba odrzuconych obrazów: 12\n",
      "Kształt train_images_np: (1618, 128, 128, 3)\n",
      "Kształt train_masks_np: (1618, 128, 128)\n",
      "Kształt test_images_np: (688, 128, 128, 3)\n",
      "Kształt test_masks_np: (688, 128, 128)\n",
      "Processed train images shape: (1618, 128, 128, 3)\n",
      "Processed train masks shape: (1618, 128, 128, 4)\n",
      "Processed test images shape: (688, 128, 128, 3)\n",
      "Processed test masks shape: (688, 128, 128, 4)\n",
      "Kształt obrazów treningowych po podziale: (1294, 128, 128, 3)\n",
      "Kształt masek treningowych po podziale: (1294, 128, 128, 4)\n",
      "Kształt obrazów walidacyjnych: (324, 128, 128, 3)\n",
      "Kształt masek walidacyjnych: (324, 128, 128, 4)\n",
      "Kształt masek przed przetwarzaniem: (1294, 128, 128, 4)\n",
      "Maski są już zakodowane w formacie one-hot, pomijam kodowanie.\n",
      "Kształt masek po przetworzeniu: (1294, 128, 128, 4)\n",
      "Kształt masek przed przetwarzaniem: (324, 128, 128, 4)\n",
      "Maski są już zakodowane w formacie one-hot, pomijam kodowanie.\n",
      "Kształt masek po przetworzeniu: (324, 128, 128, 4)\n",
      "Kształt masek przed przetwarzaniem: (688, 128, 128, 4)\n",
      "Maski są już zakodowane w formacie one-hot, pomijam kodowanie.\n",
      "Kształt masek po przetworzeniu: (688, 128, 128, 4)\n"
     ]
    }
   ],
   "source": [
    "# Załaduj i przetwórz dane\n",
    "train_images_paths, train_json = load_files('SHIDC-B-Ki-67/bare images/Train')\n",
    "test_images_paths, test_json = load_files('SHIDC-B-Ki-67/bare images/Test')\n",
    "\n",
    "# Załaduj obrazy w kolorze\n",
    "train_images = load_images(train_images_paths)\n",
    "test_images = load_images(test_images_paths)\n",
    "\n",
    "# Załaduj dane jądrowe z plików JSON\n",
    "train_nucleus_data = load_json_data(train_json)\n",
    "test_nucleus_data = load_json_data(test_json)\n",
    "\n",
    "print(f\"Liczba załadowanych obrazów treningowych: {len(train_images)}\")\n",
    "print(f\"Liczba załadowanych obrazów testowych: {len(test_images)}\")\n",
    "\n",
    "# Zmiana rozmiaru obrazów\n",
    "train_images_resized = resize_images(train_images)\n",
    "test_images_resized = resize_images(test_images)\n",
    "\n",
    "print(f\"Liczba obrazów treningowych po zmianie rozmiaru: {len(train_images_resized)}\")\n",
    "print(f\"Liczba obrazów testowych po zmianie rozmiaru: {len(test_images_resized)}\")\n",
    "\n",
    "# Konwersja obrazów na format RGB\n",
    "train_images_resized = [np.array(img.convert(\"RGB\")) for img in train_images_resized]\n",
    "test_images_resized = [np.array(img.convert(\"RGB\")) for img in test_images_resized]\n",
    "\n",
    "# Utwórz maski na podstawie danych jądrowych\n",
    "train_masks = create_masks(IMAGE_SIZE, train_nucleus_data)\n",
    "test_masks = create_masks(IMAGE_SIZE, test_nucleus_data)\n",
    "\n",
    "# Konwersja do tablicy NumPy\n",
    "train_images_resized = np.array(train_images_resized)\n",
    "train_masks = np.array(train_masks)\n",
    "test_images_resized = np.array(test_images_resized)\n",
    "test_masks = np.array(test_masks)\n",
    "\n",
    "print(f\"Kształt obrazów treningowych: {train_images_resized.shape}\")\n",
    "print(f\"Kształt masek treningowych: {train_masks.shape}\")\n",
    "print(f\"Kształt obrazów testowych: {test_images_resized.shape}\")\n",
    "print(f\"Kształt masek testowych: {test_masks.shape}\")\n",
    "\n",
    "# Filtruj obrazy z minimalną liczbą komórek\n",
    "train_images_np, train_masks_np = filter_images_with_min_cells(train_images_resized, train_masks, min_cells=20)\n",
    "test_images_np, test_masks_np = filter_images_with_min_cells(test_images_resized, test_masks, min_cells=5)\n",
    "\n",
    "print(f\"Kształt train_images_np: {train_images_np.shape}\")\n",
    "print(f\"Kształt train_masks_np: {train_masks_np.shape}\")\n",
    "print(f\"Kształt test_images_np: {test_images_np.shape}\")\n",
    "print(f\"Kształt test_masks_np: {test_masks_np.shape}\")\n",
    "\n",
    "# Wstępne przetwarzanie obrazów i one-hot encoding masek\n",
    "train_images_np = preprocess_images(train_images_np)\n",
    "train_masks_np = one_hot_encode_masks(train_masks_np)\n",
    "\n",
    "test_images_np = preprocess_images(test_images_np)\n",
    "test_masks_np = one_hot_encode_masks(test_masks_np)\n",
    "\n",
    "print(f\"Processed train images shape: {train_images_np.shape}\")\n",
    "print(f\"Processed train masks shape: {train_masks_np.shape}\")\n",
    "print(f\"Processed test images shape: {test_images_np.shape}\")\n",
    "print(f\"Processed test masks shape: {test_masks_np.shape}\")\n",
    "\n",
    "train_images_np, val_images_np, train_masks_np, val_masks_np = train_test_split(\n",
    "    train_images_np, train_masks_np, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Kształt obrazów treningowych po podziale: {train_images_np.shape}\")\n",
    "print(f\"Kształt masek treningowych po podziale: {train_masks_np.shape}\")\n",
    "print(f\"Kształt obrazów walidacyjnych: {val_images_np.shape}\")\n",
    "print(f\"Kształt masek walidacyjnych: {val_masks_np.shape}\")\n",
    "\n",
    "train_images_np, train_masks_np = preprocess_images_and_masks(train_images_np, train_masks_np)\n",
    "val_images_np, val_masks_np = preprocess_images_and_masks(val_images_np, val_masks_np)\n",
    "test_images_np, test_masks_np = preprocess_images_and_masks(test_images_np, test_masks_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Rozmiar train_images_np: {train_images_np.shape}\")\n",
    "\n",
    "index = 330\n",
    "plt.imshow(train_images_np[index])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(np.argmax(train_masks_np[index], axis=-1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trenowanie modelu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_list = [[8, 16, 32, 64, 128]]\n",
    "\n",
    "\n",
    "batch_size_list = [2, 4, 10, 16]\n",
    "\n",
    "\n",
    "epochs_list = [100, 200]\n",
    "\n",
    "run_training(train_images_np, train_masks_np, val_images_np, val_masks_np, test_images_np, test_masks_np, filters_list, batch_size_list, epochs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ewaluacja modelu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = './Model'\n",
    "\n",
    "evaluate_models_in_folders(models_folder, test_images_np, test_masks_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trening pojedynczej sieci U-Net z 128 filtrami, batch_size = 4, epochs = 100\n",
      "\n",
      "Wagi klas: [0.00422225 0.07732831 0.03639482 0.88205462]\n",
      "Epoch 1/100\n",
      "322/323 [============================>.] - ETA: 0s - loss: 0.2917 - accuracy: 0.7949 - precision: 0.7964 - recall: 0.7024 - iou_metric: 0.4697\n",
      "Epoch 1: val_loss improved from inf to 0.28209, saving model to Model/1_unets_128_filters\\best_model_1_unets_128_filters_100_epoch_4_batch.h5\n",
      "323/323 [==============================] - 16s 31ms/step - loss: 0.2918 - accuracy: 0.7947 - precision: 0.7962 - recall: 0.7026 - iou_metric: 0.4698 - val_loss: 0.2821 - val_accuracy: 0.8516 - val_precision: 0.8792 - val_recall: 0.8134 - val_iou_metric: 0.5695 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.7360 - precision: 0.7804 - recall: 0.7418 - iou_metric: 0.5320\n",
      "Epoch 2: val_loss did not improve from 0.28209\n",
      "323/323 [==============================] - 9s 27ms/step - loss: 0.2611 - accuracy: 0.7360 - precision: 0.7804 - recall: 0.7418 - iou_metric: 0.5320 - val_loss: 0.3157 - val_accuracy: 0.8598 - val_precision: 0.8645 - val_recall: 0.8536 - val_iou_metric: 0.6390 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 0.2568 - accuracy: 0.7337 - precision: 0.7785 - recall: 0.7483 - iou_metric: 0.5419\n",
      "Epoch 3: val_loss did not improve from 0.28209\n",
      "323/323 [==============================] - 11s 33ms/step - loss: 0.2568 - accuracy: 0.7337 - precision: 0.7785 - recall: 0.7483 - iou_metric: 0.5419 - val_loss: 0.2840 - val_accuracy: 0.8652 - val_precision: 0.8733 - val_recall: 0.8559 - val_iou_metric: 0.6660 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "322/323 [============================>.] - ETA: 0s - loss: 0.2531 - accuracy: 0.7392 - precision: 0.7828 - recall: 0.7569 - iou_metric: 0.5520\n",
      "Epoch 4: val_loss did not improve from 0.28209\n",
      "323/323 [==============================] - 11s 35ms/step - loss: 0.2531 - accuracy: 0.7392 - precision: 0.7828 - recall: 0.7570 - iou_metric: 0.5522 - val_loss: 0.3003 - val_accuracy: 0.8634 - val_precision: 0.8659 - val_recall: 0.8604 - val_iou_metric: 0.7016 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 0.2511 - accuracy: 0.7390 - precision: 0.7822 - recall: 0.7593 - iou_metric: 0.5551\n",
      "Epoch 5: val_loss did not improve from 0.28209\n",
      "323/323 [==============================] - 11s 34ms/step - loss: 0.2511 - accuracy: 0.7390 - precision: 0.7822 - recall: 0.7593 - iou_metric: 0.5551 - val_loss: 0.2876 - val_accuracy: 0.8608 - val_precision: 0.8695 - val_recall: 0.8496 - val_iou_metric: 0.5854 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 0.2494 - accuracy: 0.7431 - precision: 0.7871 - recall: 0.7635 - iou_metric: 0.5609\n",
      "Epoch 6: val_loss did not improve from 0.28209\n",
      "323/323 [==============================] - 11s 34ms/step - loss: 0.2494 - accuracy: 0.7431 - precision: 0.7871 - recall: 0.7635 - iou_metric: 0.5609 - val_loss: 0.3602 - val_accuracy: 0.8571 - val_precision: 0.8576 - val_recall: 0.8565 - val_iou_metric: 0.7460 - lr: 9.0484e-04\n",
      "Epoch 7/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 0.2483 - accuracy: 0.7437 - precision: 0.7867 - recall: 0.7672 - iou_metric: 0.5639\n",
      "Epoch 7: val_loss did not improve from 0.28209\n",
      "323/323 [==============================] - 11s 34ms/step - loss: 0.2483 - accuracy: 0.7437 - precision: 0.7867 - recall: 0.7672 - iou_metric: 0.5639 - val_loss: 0.3035 - val_accuracy: 0.8604 - val_precision: 0.8640 - val_recall: 0.8573 - val_iou_metric: 0.7149 - lr: 8.1873e-04\n",
      "Epoch 8/100\n",
      "322/323 [============================>.] - ETA: 0s - loss: 0.2479 - accuracy: 0.7437 - precision: 0.7870 - recall: 0.7662 - iou_metric: 0.5636\n",
      "Epoch 8: val_loss did not improve from 0.28209\n",
      "323/323 [==============================] - 10s 32ms/step - loss: 0.2480 - accuracy: 0.7437 - precision: 0.7868 - recall: 0.7664 - iou_metric: 0.5637 - val_loss: 0.3185 - val_accuracy: 0.8635 - val_precision: 0.8649 - val_recall: 0.8617 - val_iou_metric: 0.7439 - lr: 7.4082e-04\n",
      "Epoch 9/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 0.2460 - accuracy: 0.7468 - precision: 0.7895 - recall: 0.7713 - iou_metric: 0.5695\n",
      "Epoch 9: val_loss improved from 0.28209 to 0.26745, saving model to Model/1_unets_128_filters\\best_model_1_unets_128_filters_100_epoch_4_batch.h5\n",
      "323/323 [==============================] - 9s 28ms/step - loss: 0.2460 - accuracy: 0.7468 - precision: 0.7895 - recall: 0.7713 - iou_metric: 0.5695 - val_loss: 0.2675 - val_accuracy: 0.8648 - val_precision: 0.8745 - val_recall: 0.8551 - val_iou_metric: 0.6870 - lr: 6.7032e-04\n",
      "Epoch 10/100\n",
      "321/323 [============================>.] - ETA: 0s - loss: 0.2458 - accuracy: 0.7481 - precision: 0.7912 - recall: 0.7723 - iou_metric: 0.5700\n",
      "Epoch 10: val_loss did not improve from 0.26745\n",
      "323/323 [==============================] - 9s 27ms/step - loss: 0.2458 - accuracy: 0.7480 - precision: 0.7912 - recall: 0.7722 - iou_metric: 0.5699 - val_loss: 0.3107 - val_accuracy: 0.8565 - val_precision: 0.8611 - val_recall: 0.8529 - val_iou_metric: 0.7142 - lr: 6.0653e-04\n",
      "Epoch 11/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 0.2444 - accuracy: 0.7485 - precision: 0.7915 - recall: 0.7738 - iou_metric: 0.5726\n",
      "Epoch 11: val_loss did not improve from 0.26745\n",
      "323/323 [==============================] - 10s 32ms/step - loss: 0.2444 - accuracy: 0.7485 - precision: 0.7915 - recall: 0.7738 - iou_metric: 0.5726 - val_loss: 0.3115 - val_accuracy: 0.8579 - val_precision: 0.8619 - val_recall: 0.8548 - val_iou_metric: 0.7316 - lr: 5.4881e-04\n",
      "Epoch 12/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 0.2447 - accuracy: 0.7488 - precision: 0.7921 - recall: 0.7742 - iou_metric: 0.5719\n",
      "Epoch 12: val_loss did not improve from 0.26745\n",
      "323/323 [==============================] - 11s 34ms/step - loss: 0.2447 - accuracy: 0.7488 - precision: 0.7921 - recall: 0.7742 - iou_metric: 0.5719 - val_loss: 0.2786 - val_accuracy: 0.8641 - val_precision: 0.8701 - val_recall: 0.8586 - val_iou_metric: 0.7166 - lr: 4.9659e-04\n",
      "Epoch 13/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 0.2425 - accuracy: 0.7499 - precision: 0.7926 - recall: 0.7770 - iou_metric: 0.5767\n",
      "Epoch 13: val_loss did not improve from 0.26745\n",
      "323/323 [==============================] - 10s 31ms/step - loss: 0.2425 - accuracy: 0.7499 - precision: 0.7926 - recall: 0.7770 - iou_metric: 0.5767 - val_loss: 0.3418 - val_accuracy: 0.8581 - val_precision: 0.8599 - val_recall: 0.8569 - val_iou_metric: 0.7389 - lr: 4.4933e-04\n",
      "Epoch 14/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.7514 - precision: 0.7939 - recall: 0.7783 - iou_metric: 0.5765\n",
      "Epoch 14: val_loss did not improve from 0.26745\n",
      "323/323 [==============================] - 11s 35ms/step - loss: 0.2435 - accuracy: 0.7514 - precision: 0.7939 - recall: 0.7783 - iou_metric: 0.5765 - val_loss: 0.3215 - val_accuracy: 0.8616 - val_precision: 0.8632 - val_recall: 0.8601 - val_iou_metric: 0.7430 - lr: 4.0657e-04\n",
      "Epoch 15/100\n",
      "322/323 [============================>.] - ETA: 0s - loss: 0.2421 - accuracy: 0.7528 - precision: 0.7947 - recall: 0.7810 - iou_metric: 0.5792\n",
      "Epoch 15: val_loss did not improve from 0.26745\n",
      "323/323 [==============================] - 11s 33ms/step - loss: 0.2421 - accuracy: 0.7527 - precision: 0.7947 - recall: 0.7809 - iou_metric: 0.5791 - val_loss: 0.3119 - val_accuracy: 0.8630 - val_precision: 0.8648 - val_recall: 0.8616 - val_iou_metric: 0.7457 - lr: 3.6788e-04\n",
      "Epoch 16/100\n",
      "322/323 [============================>.] - ETA: 0s - loss: 0.2422 - accuracy: 0.7513 - precision: 0.7933 - recall: 0.7797 - iou_metric: 0.5777\n",
      "Epoch 16: val_loss did not improve from 0.26745\n",
      "323/323 [==============================] - 11s 34ms/step - loss: 0.2422 - accuracy: 0.7511 - precision: 0.7932 - recall: 0.7796 - iou_metric: 0.5776 - val_loss: 0.3261 - val_accuracy: 0.8608 - val_precision: 0.8618 - val_recall: 0.8595 - val_iou_metric: 0.7248 - lr: 3.3287e-04\n",
      "Epoch 17/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 0.2420 - accuracy: 0.7515 - precision: 0.7939 - recall: 0.7794 - iou_metric: 0.5771\n",
      "Epoch 17: val_loss did not improve from 0.26745\n",
      "323/323 [==============================] - 11s 34ms/step - loss: 0.2420 - accuracy: 0.7515 - precision: 0.7939 - recall: 0.7794 - iou_metric: 0.5771 - val_loss: 0.3142 - val_accuracy: 0.8593 - val_precision: 0.8618 - val_recall: 0.8573 - val_iou_metric: 0.7353 - lr: 3.0119e-04\n",
      "Epoch 18/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 0.2413 - accuracy: 0.7536 - precision: 0.7955 - recall: 0.7812 - iou_metric: 0.5811\n",
      "Epoch 18: val_loss did not improve from 0.26745\n",
      "323/323 [==============================] - 11s 34ms/step - loss: 0.2413 - accuracy: 0.7536 - precision: 0.7955 - recall: 0.7812 - iou_metric: 0.5811 - val_loss: 0.3148 - val_accuracy: 0.8651 - val_precision: 0.8673 - val_recall: 0.8632 - val_iou_metric: 0.7520 - lr: 2.7253e-04\n",
      "Epoch 19/100\n",
      "323/323 [==============================] - ETA: 0s - loss: 0.2407 - accuracy: 0.7567 - precision: 0.7978 - recall: 0.7820 - iou_metric: 0.5806\n",
      "Epoch 19: val_loss did not improve from 0.26745\n",
      "323/323 [==============================] - 11s 34ms/step - loss: 0.2407 - accuracy: 0.7567 - precision: 0.7978 - recall: 0.7820 - iou_metric: 0.5806 - val_loss: 0.3050 - val_accuracy: 0.8635 - val_precision: 0.8662 - val_recall: 0.8611 - val_iou_metric: 0.7400 - lr: 2.4660e-04\n",
      "Epoch 20/100\n",
      "322/323 [============================>.] - ETA: 0s - loss: 0.2408 - accuracy: 0.7573 - precision: 0.7979 - recall: 0.7831 - iou_metric: 0.5814\n",
      "Epoch 20: val_loss did not improve from 0.26745\n",
      "323/323 [==============================] - 11s 35ms/step - loss: 0.2408 - accuracy: 0.7573 - precision: 0.7979 - recall: 0.7830 - iou_metric: 0.5813 - val_loss: 0.3177 - val_accuracy: 0.8626 - val_precision: 0.8646 - val_recall: 0.8612 - val_iou_metric: 0.7466 - lr: 2.2313e-04\n",
      "22/22 [==============================] - 1s 16ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Background       0.88      0.97      0.93   9544150\n",
      "   Pozytywne       0.74      0.46      0.56    542332\n",
      "   Negatywne       0.67      0.13      0.22   1137705\n",
      "         TLL       0.12      0.47      0.20     48005\n",
      "\n",
      "    accuracy                           0.86  11272192\n",
      "   macro avg       0.60      0.51      0.48  11272192\n",
      "weighted avg       0.85      0.86      0.83  11272192\n",
      "\n",
      "Liczba wszystkich komórek: 21471\n",
      "Liczba pozytywnych komórek: 9748\n",
      "Liczba negatywnych komórek: 10806\n",
      "Liczba komórek TLL: 917\n",
      "Wykryte pozytywne komórki: 9006\n",
      "Wykryte negatywne komórki: 14183\n",
      "Wykryte komórki TLL: 4958\n",
      "Procent wykrytych pozytywnych komórek: 92.39%\n",
      "Procent wykrytych negatywnych komórek: 131.25%\n",
      "Procent wykrytych komórek TLL: 540.68%\n",
      "Procent wykrytych wszystkich komórek: 131.09%\n",
      "Precyzja: 0.68\n",
      "Czułość (Recall): 0.24\n",
      "F1-Score: 0.33\n",
      "22/22 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "num_filters = [8, 16, 32, 64, 128]\n",
    "epochs = 100\n",
    "batch_size = 4\n",
    "unet_size = 1  \n",
    "\n",
    "K.clear_session()\n",
    "print(f\"\\nTrening pojedynczej sieci U-Net z {num_filters[-1]} filtrami, batch_size = {batch_size}, epochs = {epochs}\\n\")\n",
    "\n",
    "train_images_np = np.array([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) if len(img.shape) == 2 else img for img in train_images_np])\n",
    "val_images_np = np.array([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) if len(img.shape) == 2 else img for img in val_images_np])\n",
    "test_images_np = np.array([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) if len(img.shape) == 2 else img for img in test_images_np])\n",
    "\n",
    "model, history = train_model(\n",
    "    train_images_np, train_masks_np,\n",
    "    val_images_np, val_masks_np,\n",
    "    test_images_np, test_masks_np,\n",
    "    num_filters=num_filters,\n",
    "    epochs=epochs, batch_size=batch_size,\n",
    "    unet_size=unet_size\n",
    ")\n",
    "\n",
    "save_folder = f'Model/{unet_size}_unet_{num_filters[-1]}_filters'\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "plot_training_history(history, save_folder, filters=num_filters[-1], epochs=epochs)\n",
    "\n",
    "\n",
    "evaluate_model_with_channels(model, \"Single U-Net\", test_images_np, test_masks_np)\n",
    "\n",
    "\n",
    "mask_save_folder = \"./maski\"\n",
    "os.makedirs(mask_save_folder, exist_ok=True)\n",
    "\n",
    "predictions = model.predict(test_images_np)\n",
    "y_pred_labels = np.argmax(predictions, axis=-1)\n",
    "\n",
    "for i, (image_path, mask) in enumerate(zip(test_images_paths, y_pred_labels)):\n",
    "    mask_filename = os.path.join(mask_save_folder, os.path.splitext(os.path.basename(image_path))[0] + \".npy\")\n",
    "    np.save(mask_filename, mask)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
